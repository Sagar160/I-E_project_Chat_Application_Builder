{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acaa5e32-f6eb-47eb-8394-347fc9fee89b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321ae8b6-44de-46f1-b45c-1d72a085ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pypdf import PdfReader \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a0959c-b637-43fb-83a4-316a1d5c770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, ChatSession, Part\n",
    "from vertexai.language_models import TextEmbeddingModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b1f3c-c6e4-4fa0-809b-1ff5d25761fd",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9769b52-6b3c-4c35-87fd-7bddf9c90d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/spanwar/Documents/collage/projects/chatbot_v2/vertex_key/oval-smile-417517-43cf867c95fd.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9842ba04-dfac-48b3-aac5-717a764aa8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"oval-smile-417517\"\n",
    "location   = \"us-central1\"\n",
    "vertexai.init(project=project_id, location=location)\n",
    "\n",
    "model = GenerativeModel(\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333afa6e-6a96-419d-b2fe-7312ffd2d757",
   "metadata": {},
   "source": [
    "# Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d902748-7ed3-406a-9699-7495b6b700f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_response(prompt: str):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eadd9653-75da-4097-8a7f-a72d62a868ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_to_text(response):\n",
    "    return response.text\n",
    "        # return str(response.candidates[0].content.parts[0]).split('text: \"')[-1].split('\"\\n')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cddc06e0-0247-4a6b-ac46-f2a4f2f7d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini(message):\n",
    "    message = message\n",
    "    response = get_chat_response(message)\n",
    "    txt_output = response_to_text(response)\n",
    "    return txt_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e61285-e19d-4f8d-ae47-4c8c761b785d",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9c69e-57a6-4694-b65d-a542d3514ad9",
   "metadata": {},
   "source": [
    "## QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f678381-e8c8-49d8-8d2e-a4c997a9ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(path):\n",
    "    '''\n",
    "    find files from the directory\n",
    "    '''\n",
    "    if os.path.exists(path):\n",
    "        if os.path.isdir(path):\n",
    "            files = []\n",
    "            for root, _, filenames in os.walk(path):\n",
    "                for filename in filenames:\n",
    "                    files.append(os.path.join(root, filename))\n",
    "            return files\n",
    "        elif os.path.isfile(path):\n",
    "            return [path]\n",
    "        else:\n",
    "            raise Exception('Unable to read directory')\n",
    "    else:\n",
    "        raise Exception('Path does not exsts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6029e814-28b9-4d8d-8749-ad983ab6b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file_ext(path):\n",
    "    '''\n",
    "    return file extension.\n",
    "    '''\n",
    "    file_name, file_extension = os.path.splitext(path)\n",
    "    return file_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "880569ce-45ed-4b03-ba57-916568046479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(path):\n",
    "    '''\n",
    "    Read pdf file.\n",
    "    '''\n",
    "    # creating a pdf reader object \n",
    "    reader = PdfReader(path) \n",
    "    text   = ''\n",
    "    for i in range(len(reader.pages)): \n",
    "        # getting a specific page from the pdf file \n",
    "        page = reader.pages[i] \n",
    "        # extracting text from page \n",
    "        text = text + page.extract_text() \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef47949a-1269-4a48-a52f-2b42133fb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(path):\n",
    "    with open(path, 'r') as f:\n",
    "        content = f.read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f306add-74a6-4c73-8b71-61ab5f76a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_words(text):\n",
    "    return len(text.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84002dd7-83b5-44a1-ac1f-691b90feaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_directory_files(path):\n",
    "    files     = find_files(path)\n",
    "    text_data = {}\n",
    "    \n",
    "    for file in files:\n",
    "        print(f'Reading the file: {file}')\n",
    "        extension = find_file_ext(file)\n",
    "        if extension=='.pdf':\n",
    "            text = read_pdf(file)\n",
    "            text_data[file] = {'len': text_words(text),\n",
    "                               'text': text\n",
    "                              }\n",
    "        elif extension=='.rtf':\n",
    "            text = read_text(file)\n",
    "            text_data[file] = {'len': text_words(text),\n",
    "                               'text': text\n",
    "                              }\n",
    "        else:\n",
    "            text = read_text(file)\n",
    "            text_data[file] = {'len': text_words(text),\n",
    "                               'text': text\n",
    "                              }\n",
    "\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8d8f996-bac7-4e02-a34d-0892443caafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_emb_vectorizer(vectorizer, path):\n",
    "    joblib.dump(vectorizer, path)  # Save the model to a file\n",
    "\n",
    "def load_emb_vectorizer(path):\n",
    "    # Load the saved moded\n",
    "    return joblib.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "233cee7d-4e22-4850-ac04-9fcdf45d2158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(data):\n",
    "    texts    = []\n",
    "    for key in data:\n",
    "        texts.append(data[key]['text'])\n",
    "        \n",
    "    vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,2), stop_words = \"english\", lowercase = True, max_features = 10000)\n",
    "    embeddings = vectorizer.fit_transform(texts).toarray()\n",
    "    for index, key in enumerate(data):\n",
    "        data[key]['emb'] = embeddings[index]\n",
    "    \n",
    "    return data, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "103b3c50-bde8-4c85-9584-bdaaa25e701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_from_vectorizer(text, vectorizer):\n",
    "    return vectorizer.transform([text]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "945e2017-e71d-4913-9c7b-6d1b2008bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_text(doc_emb, emb, top_doc):\n",
    "    similarities = cosine_similarity(emb, doc_emb)\n",
    "    sorted_indices = np.argsort(similarities[0])[::-1]  # Sort in descending order\n",
    "    top_indices = sorted_indices[:top_doc]\n",
    "    return top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d2a93569-e1b4-4236-bfc9-57704abc7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_doc(text, data, top_index, vectorizer):\n",
    "    text_emb = create_embedding_from_vectorizer(text, vectorizer)\n",
    "    doc_emb  = [data[i]['emb'] for i in data]\n",
    "    indexs = get_similar_text(doc_emb, text_emb, top_index)\n",
    "\n",
    "    similar_doc = ''\n",
    "    for i, index in enumerate(indexs):\n",
    "        file  = list(data.keys())[index]\n",
    "        similar_doc =  similar_doc + f'Doc {i}\\n' + data[file]['text']\n",
    "\n",
    "    return similar_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "32484815-b96e-466c-8067-a741af4be496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def write_json(file_path, data):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b194e15-4e14-4c21-b805-d5eb5791734d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5cb6b918-e9e3-4de3-95d1-05dbe51fbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(path, botname):\n",
    "    text_data = read_directory_files(path)\n",
    "    data_index, vectorizer = create_embedding(text_data)\n",
    "\n",
    "    np.save(f'data/qna_save_data/{botname}_qna.npy', data_index)\n",
    "    save_emb_vectorizer(vectorizer, f'data/qna_save_data/{botname}_vec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "96a1bc43-6d44-4d32-b23d-d2803be8e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_qna(path, botname):\n",
    "    process_data(path, botname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aeb58d9b-2113-4387-a0df-01e0914c7487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qna(question, botname):\n",
    "    # Load data\n",
    "    data_index = np.load(f'data/qna_save_data/{botname}_qna.npy', allow_pickle=True)\n",
    "    vectorizer = load_emb_vectorizer(f'data/qna_save_data/{botname}_vec.pkl')\n",
    "    data_index = data_index.tolist()\n",
    "    # Search doc\n",
    "    message = search_doc(question, data_index, 2, vectorizer)\n",
    "    message = message + f'\\n#####\\nUsing above data Please answer this question. Please write atmax 100 words only.: {question}'\n",
    "    # call\n",
    "    answer = call_gemini(message)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "26d237dd-1444-4967-b23e-5a3159ee64a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/leanStartupData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "24c415ad-391b-4e43-91de-700bc79daa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the file: data/leanStartupData/LDBD23intro.pdf\n",
      "Reading the file: data/leanStartupData/LeanStartup.pdf\n",
      "Reading the file: data/leanStartupData/Platform.pdf\n",
      "Reading the file: data/leanStartupData/LearningLog.rtf\n"
     ]
    }
   ],
   "source": [
    "initialize_qna(path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "beff2914-9e83-45f0-b0a6-eba83222fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = qna('what is the lean to startup?. Also explain about the business model', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "083ad55d-689e-4fd5-952b-e199a8d75cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Lean Startup** is a method that helps businesses to create new products and services in a fast and efficient way. It is based on the idea of \"build, measure, learn\" and involves testing ideas with customers early and often, then iterating based on feedback.\n",
      "\n",
      "A **business model** is a plan for how a business will generate revenue and make a profit. It describes the business's products or services, target market, sales and marketing strategies, and financial plan. A lean startup approach to business model design involves testing and iterating on the business model as the business learns more about its customers and market.\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "337b6124-9186-4fba-a84e-00dd47b612eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans2 = qna('can you help me how to write learning log. I am little confused.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdd5db8e-0d25-4667-946f-a293eaf7e75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**How to Write a Learning Log:**\n",
      "\n",
      "1. **Start** with the week number (e.g., W4).\n",
      "2. **Answer** the provided themes (e.g., What inspired you this week?).\n",
      "3. **Reflect** on your experiences and learning in practice.\n",
      "4. **Write** in an unstructured and conversational style.\n",
      "5. **Focus** on:\n",
      "    - Inspirations and surprises\n",
      "    - Innovation and idea generation\n",
      "    - Business development\n",
      "    - Stakeholder collaboration\n",
      "    - Technology and software development\n",
      "    - Teamwork\n",
      "    - Learning sources (mentors, team, stakeholders)\n",
      "6. **Use** the learning log as a weekly checklist to reflect on your progress.\n",
      "7. **Keep** a single document for all entries.\n"
     ]
    }
   ],
   "source": [
    "print(ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc688d-55fb-488a-a843-8100471aa4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini_env_v2",
   "language": "python",
   "name": "gemini_env_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
